# Transformer-Machine_Translation

This repository contains my **from-scratch implementation of the Transformer architecture for machine translation, based on the paper **â€œAttention Is All You Needâ€.

The project is being developed **step by step toward a full translation system.  
At the current stage, the "Transformer encoder is implemented first" to build a strong foundation before adding the decoder and training pipeline.

---

## Why I built this

Most tutorials use high-level APIs like 'nn.Transformer', which hide important internal details.  
I wanted to understand "how Transformers actually work internally", especially for translation tasks.

My goals were to:

- Understand "self-attention" step by step"
- Learn why embeddings are scaled by 'âˆšd_model'
- Understand what "Q Â· Káµ€" represents
- See how multiplying with 'V' gives meaningful word information
- Clearly understand the role of **residual (skip) connections**
- Track **tensor shapes** inside attention

---

## Input Embedding and Scaling (Why âˆšd_model?)

Token IDs are first converted into vectors using an embedding layer.

In the forward pass, the embedding output is multiplied by `âˆšd_model`:


Embedding(x) * âˆšd_model

Why this is done:
Embedding values are usually small
Attention uses dot products (Q Â· Káµ€)
Without scaling, dot-product values become too small
Small values entering softmax reduce learning effectiveness
Scaling by âˆšd_model keeps values stable and improves training behavior.

## Positional Encoding

Transformers do not process tokens sequentially, so they do not know word order by default.

Sinusoidal positional encoding is added to embeddings so that:
     -Each position has a unique representation
     -The model can learn the order of words in a sentence

## Multi-Head Self-Attention (Intuition + Shapes)
# Creating Q, K, and V

Input shape:
(batch_size, seq_len, d_model)

After linear projection:
Q, K, V â†’ (batch_size, seq_len, d_model)

After splitting into heads:
(batch_size, num_heads, seq_len, d_k)

# Q Â· Káµ€ â€” How words are related
 Q @ Káµ€


 Resulting shape:

 (batch_size, num_heads, seq_len, seq_len)


# Meaning:
    Each word is compared with every other word
    This step measures how strongly words are related
    It answers the question:
    â€œWhich words should this word pay attention to?â€
At this stage, this gives relationships, not information.

# Softmax â€” Importance scores
Softmax converts relationship scores into attention weights:
   Higher weight â†’ more important word
   Lower weight â†’ less important word

#Multiply with V â€” Getting information
    Attention = softmax(QKáµ€ / âˆšd_k) @ V
    Output shape:
    (batch_size, num_heads, seq_len, d_k)

   # Why multiply with V:
       Q Â· Káµ€ tells which words matter
       V contains the actual information of each word
       Multiplication mixes word information based on importance

   #In simple terms:
      QKáµ€ â†’ relationship
      V â†’ information

## Residual Connections (Skip Connections)

After each major sub-layer (attention and feed-forward), a residual connection is applied:
Output = x + Sublayer(x)
This is followed by layer normalization.
Why residual connections are important:
    They allow gradients to flow easily
    Prevent vanishing gradient problems
    Make deep Transformer stacks train stably

Residual connections are used with:
      Multi-head self-attention
      Feed-forward network

## Encoder Block Structure
Input
 â†’ Multi-Head Self-Attention
 â†’ Add (skip connection) + LayerNorm
 â†’ Feed-Forward Network
 â†’ Add (skip connection) + LayerNorm
 â†’ Output


Multiple encoder blocks are stacked to form the complete encoder.

## Code structure
Transformer/
â”‚
â”œâ”€â”€ model.py      # Transformer encoder implementation
â”œâ”€â”€ README.md


All components are implemented manually to ensure clarity and deep understanding.

## Current status
âœ… Transformer encoder implemented
ğŸš§ Decoder (masked self-attention + encoderâ€“decoder attention) coming next
ğŸš§ Training and translation inference to be added later

## What I learned from this
Why embedding scaling is important
How attention models word relationships
How values carry actual semantic information
Why residual connections are critical in deep networks
How tensor shapes evolve inside attention

## Tech used
# Python
# PyTorch

## References
Attention Is All You Need â€” Vaswani et al.
PyTorch documentation

## Author
Subhasis Dash
B.Tech student
Learning Transformers for machine translation from first principles


---

